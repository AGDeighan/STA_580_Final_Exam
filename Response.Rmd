---
title: "STA 580 Final Exam"
author: "Andrew Deighan"
date: "April 29, 2017"
output: html_document
---

# Answers

<br>

## Question 1

  For code see [appendix](#a1).
  
> An educator believes that a new reading curriculum will help elementary school students improve some aspects of their reading ability. She arranges for a third-grade class of 21 students to take part in the new curriculum for an eight-week period. A control classroom of 23 third-graders follows the standard curriculum. At the end of the eight weeks, all students are given a Degree of Reading Power (DRP) test, which measures aspects of reading that the treatment is designed to improve “DRPscores.txt”.
>
> Test the hypothesis that the treatment group performed better than the control group on the test. State your conclusions.

```{r, include = F}

q1.data <- data.frame(read.table("data/DRPscores.txt", header = F, sep = ""))
colnames(q1.data) <- c("Group", "Score")
q1.data.treat <- q1.data[q1.data$Group == "Treat",]
q1.data.contr <- q1.data[q1.data$Group == "Control",]

```

  The size of our control group is 23 and the size of our treatment group is 21. Since these sample sizes are both less than 30 we should use a t-test of sample means. Before doing so however, we need to check that our assumption that the data are normally distributed is valid. To this end we will use the Shapiro-Wilk test for normality. The null hypothesis of the Shapiro-Wilk test is that the data are normally distributed and the alternative hypothesis is that they are not. Thus a small p-value (less than 0.05) indicates that the data are *not* normally distributed whereas a large p-value indicates that there is no significant evidence that the data are not normally distributed. Table 1 gives the p-values for the Shapiro-Wilk test for both groups. The large p-values indicate that we fail to reject the null hypothesis and conclude that the data are normally distributed.
  
```{r, include=F}

Nt.c <- shapiro.test(q1.data.contr$Score)
Nt.t <- shapiro.test(q1.data.treat$Score)

```

```{r, echo =F, results = "asis"}
library(pander)
panderOptions("table.caption.prefix", "")

x <- data.frame(Group = c("Treatment", "Control"), "P-Value" = c(Nt.t$p.value, Nt.c$p.value) )

pandoc.table(x,
             caption = "**Table 1:** P-values for Shapiro-Wilk tests for normality. The large p-values for both groups indicate that there is no evidence that either group is *not* normally distributed.",
             split.table = Inf)

```

  Next we need to test if the variances of the underlying populations for the two samples is significantly different. For this we will use an F-test for the equality of population variances. The null hypothesis for the F-test is that the two population variances are equal, the alternative is that they are not equal (for the two-tailed scenario, which is what we are interested in). The test-statistic for the F-test is the ratio of the two sample variances (sample 1 variance to sample 2 variance), the further away from 1 the test-statistic is the more likely it is that the null hypothesis is false. Under the null hypothesis (that the two population variances are equal), the test-statistic has an F-distribution with numerator degrees of freedom equal to the size of first sample minus 1, and denominator degrees of freedom equal to the size of the second sample minus 1. See below.

  $$ \text{F} = \frac{S_1^2}{S_2^2} \sim F_{(n_1 - 1)(n_2 - 2)} $$

  We can use the "var.test()" function in R to perform the above described F-test. For small p-values (< 0.05) we should reject the null hypothesis that the population variances are equal in favor of the alternative hypothesis that they are different. For large p-value we should fail to reject the null hypothesis and conclude that the population variances are equal. Table 2 reports the calculated F-statistic and corresponding p-value. The p-value is greater than 0.05 so we fail to reject the null hypothesis and conclude that the two populations have the same variance.
  
```{r, include=F}

VT <- var.test(q1.data.treat$Score, q1.data.contr$Score)

```
  

```{r, echo=F, results="asis"}

x <- data.frame("F" = VT$statistic, "P-Value" = VT$p.value)

pandoc.table(x,
             caption = "**Table 2:** Test statistic corresponding p-value for test of equality of variances. Since the p-value is greater than 0.05 (even if just so) we will conclude that the population variances can be assumed similar.",
             split.table = Inf)

```

  Now that we have verified our assumptions that the two populations have are normally distributed with equal variances, we will perform a one-tailed two-sample t-test for the difference of means. Our null hypothesis is that the mean score of students taught with the new curriculum is no greater than students taught under the old curriculum; our alternative hypothesis is that the mean score is higher.
  
  $$ \text{H}_o: \mu_t - \mu_c \leq 0 \space \space \space \space \space v.s. \space \space \space \space \text{H}_a: \mu_t - \mu_c > 0$$
  The test-statistic for this test is the difference between the sample means divided by the pooled sample variance. Under the null hypothesis this test-statistic has a t-distribution with degrees of freedom equal to the sum of the sample sizes minus 2.
  
  $$ \text{T} = \frac{\bar{x_t} - \bar{x_c}}{S_p  \sqrt{ \frac{1}{n_1} + \frac{1}{n_2} }} \sim{t_{n_1 + n_2 - 2}} \\  \\ \text{where:} \space \space \space S_p = \sqrt{ \frac{ (n_1 -1)S_1^2 + (n_2 - 1)S_2^2 }{n_1 + n_2 - 2} }$$

  The large a positive test-statistic we observe the more likely it is that the mean score of students taught under the new curriculum is greater than that of those taught under the old curriculum. We will use and alpha level of 0.05, so we will reject our null hypothesis if the p-value (probability of observing a value larger than the one we observe) of our observed test-stastic is less than 0.05. We can use the R function "t.test()" to perform this test. Table 3 reports observed test-statistic and corresponding p-value.
  
```{r, include=F}

tT <- t.test(x = q1.data.treat$Score, y = q1.data.contr$Score, alternative = "greater", var.equal = T)

```

```{r, echo=F, results="asis"}

x <- data.frame("T" = tT$statistic, "P-Value" = tT$p.value)
rownames(x) <- NULL

pandoc.table(x,
             caption = "**Table 3:** Test-statistc and corresponding p-value for one-tailed two-sample t-test.",
             split.table = Inf)

```

  Since our p-value is less than 0.05 we reject the null hypothesis that the mean scores did not differ in favor of the alternative hypothesis that they did. Thus, we conclude that the students taught under the new curriculum performed better on the test than students taught under the old curriculum.

<br>
<br>

## Question 2

  For code see [appendix](#a2)

> A company is rated as acceptable in quality control if more than 90% of units produced at
its facilities are found to be defect-free, and it is rated as excellent in quality control if
more than 95% are defect-free. Suppose that a random sample of 500 units is selected and
tested for defects, and that 18 units are found to have defects.
>
>a. Does this data show at the 5% level of significance that the company is acceptable?
>b. Does it show that the company is excellent? Construct a 95% confidence interval for
proportion of defect-free units.
>c. What sample size should a reliability engineer use to estimate this proportion to within
2% with 95% confidence if it is assumed that the proportion of units that are defect-free
is at least 90%?

  Estimated proportion defect-free:
  
  $$ \widehat{p} = \frac{500 - 18}{500} = .964 \rightarrow 96.4\% $$
  Approximate standard error of the proportion defect free:
  
  $$ \widehat{\text{SE}}[\widehat{p}] = \sqrt{\frac{\widehat{p}(1 - \widehat{p})}{n}} = \sqrt{\frac{.964*.036}{500}} \approx 0.00833 $$

<br>

### Part A

  One-tailed hypothesis test with alpha = 0.05.

* Null hypothesis The proportion of products defect-free is less than or equal to 0.90
    + $\text{p}_o \leq 0.90$
* Alternative hypothesis The proportion of products defect-free is greater than 0.90
    + $\text{p}_a > 0.90$

In order to test the above null hypothesis we will used a one-tailed Z-test with an alpha level of 0.05. The test statistic is given below:

  $$ \text{Z} = \frac{\widehat{p} - \text{p}_o}{\sqrt{\frac{\widehat{p}(1 - \widehat{p})}{n}}} \sim AN(0,1) $$

Since we are doing a one-tailed test with an alpha level of 0.05 we will reject the null hypothesis that the proportion of products defect-free is less than or equal to 0.90 in favor of the alternative that the proportion is greater than 0.90. To do this we used the "t.test()" function in R. Although this function usese a t-distribution, the t-distribution quickly approximates to normal for sample sizes above 30 so since our sample size is 500 this will not be an issue. Table Q2A reports the observed test-statistic and p-value for our test. Since the p-value is less than 0.05 (much less in fact) we reject the null hypothesis and conclude at a 5% level of significance that the company is acceptable (proportion of products defect free is greater than 0.90).

```{r, echo=F, results="asis"}

x <- c(rep(1, 482), rep(0,18))
results <- t.test(x = x, mu = 0.90, alternative = "g")

x <- data.frame("Z" = results$statistic, "P-Value" = results$p.value)
rownames(x) <- NULL

pandoc.table(x,
             caption = "**Table Q2A:** Test-statistic and corresponding p-value for one-tailed Z-test.",
             split.table = Inf)

```



<br>
<br>

### Part B

  One-tailed hypothesis test with alpha = 0.05.

* Null hypothesis The proportion of products defect-free is less than or equal to 0.95
    + $\text{p_o} \leq 0.95$
* Alternative hypothesis The proportion of products defect-free is greater than 0.95
    + $\text{p_a} > 0.95$
    
    We will conduct this hypothesis test in just the same way as in part A, except now we will use $\text{p}_o = 0.95$. Table Q2B reports the observed test-statistic and corresponding p-value. Since the p-value is less than 0.05 we reject the null hypothesis and conclude at a 5% significance level that the company is excellent (proportion of defect-free products is greater than 0.95).

```{r, echo=F, results="asis"}

x <- c(rep(1, 482), rep(0,18))
results <- t.test(x = x, mu = 0.95, alternative = "g")

x <- data.frame("Z" = results$statistic, "P-Value" = results$p.value)
rownames(x) <- NULL

pandoc.table(x,
             caption = "**Table Q2B:** Test-statistic and corresponding p-value for one-tailed Z-test.",
             split.table = Inf)

```

<br>
<br>

### Part C

  We want to determine how large the sample size *n* must be in order to have an error margin *E* of 2% ($\pm 2\%$). Below we show the formula for the sample size *n* for a desired margin of error:
  
  $$ n = \text{p}(1- \text{p})*(\frac{Z_{\alpha/2}}{E})^2 $$
  Since we want a 95% confidence interval *Z* = 1.96. We already know we want *E* to be 0.02 and the question says that p is assumed to be 0.90 thus:

$$ n = 0.9*0.1*(\frac{1.96}{0.02})^2 \approx 864.26 \rightarrow 864 $$
  So, assuming the proportion of units defect free is at least 90%, if we want to estimate the proportion of products defect free within $\pm 2\%$ with 95% confidence we should have a sample size of 864.

<br>
<br>

## Question 3

  For code see [appendix](#a3)

> A large corporation requires that its employees attend a 1-day sexual harassment seminar.
The Director of Human Resources of this corporation would like to determine whether or
not the information presented in this seminar is retained over a long period of time. To
this end, a random sample of 40 employees is selected from recently hired employees
who are scheduled to take this seminar. Each of the employees in this sample completes a
test of knowledge concerning sexual harassment and related legal issues immediately
after the seminar, and then takes a similar test 6 months later. The scores are contained in
the file “harass.txt”.
>
>Does that data indicate at the 5% level of significance that the mean score has changed
after 6 months? Construct a 95% confidence interval for the difference between the
mean scores.
  
```{r, include=F}
# Load data set

q3.data <- data.frame(read.table("data/harass.txt", header = T, sep = ""))

```

  We are dealing with paired data here (difference between test score of the same subject at different time points) so we will use a paired t-test. We can do this using the "t.test()" function in R and setting the argument "paired" to **TRUE**, this tell the function that the data is paired. Since the question just asks whether the mean score has changed, and not in what direction it has changed, this will be a two-tailed test. The null hypothesis is that the mean difference between the scores is 0, the alternative hypothesis is that it is not equal to zero. For this test we will use an alpha level of 0.05. However, before doing the test we will check to see if the data are normally distributed using the Shapiro-Wilk test. The null hypothesis is that the data are normally distributed and the alternative hypothesis is that they are not (we will use an alpha level of 0.05). R has a built in function called "shapiro.test()". Table Q3A shows the results of the Shapiro-Wilk test for the scores from test 1, test 2, and the difference between the scores. Since all the p-values are greater than 0.05 we will accept the assumption that our data are normally distributed.
  
```{r, echo=F, results="asis"}

x <- data.frame("P.value" = c(shapiro.test(q3.data$Test1)$p.value,
                              shapiro.test(q3.data$Test2)$p.value,
                              shapiro.test(q3.data$Test1 - q3.data$Test2)$p.value))
colnames(x) <- "P-Value"
rownames(x) <- c("Scores from Test 1", "Scores from Test 2", "Difference between Scores")

pandoc.table(x,
             caption = "**Table Q3A:** P-values from the Shapiro-Wilk normality test for our data. Since all the p-values are greater than 0.05 we will accept the null hypothesis that our data are normally distributed.",
             split.table = Inf)

```

  Table Q3B gives the observed test statistic and p-value for the two sample t-test for the difference between scores. Since the p-value is greater than 0.05 we will accept the null hypothesis and conclude that there is not sufficient evidence to show that the mean score has changed over 6 months.

```{r, echo=F, results="asis"}

results <- t.test(q3.data$Test2, q3.data$Test1, paired = T)

x <- data.frame("S" = results$statistic, "P" = results$p.value)
colnames(x) <- c("Test Statistic", "P-Value")

pandoc.table(x,
             caption = "**Table Q3B:** The observed test statistic and p-value for the paired t-test. Since the p-value is greater than 0.05 we cannot conclude that the mean scores changed.",
             split.table = Inf)
```

  We can also use the output from the t.test function to give us a 95% confidence for the difference between the mean scores. Table Q3C reports this confidence interval. As we can see the confidence interval includes zero, once again indicating that there is insufficient evidence of a change in the mean scores.

```{r, echo=F, results="asis"}

x <- data.frame("LB" = results$conf.int[1], "UB" = results$conf.int[2])
colnames(x) <- c("Lower Bound", "Upper Bound")

pandoc.table(x,
             caption = "**Table Q3C:** 95% confidence interval for the difference between the mean scores. Notice that the confidence interval includes 0, indicating that there is no significant evidence of a difference between the mean scores.",
             split.table = Inf)
```  

<br>
<br>

# Appendix

<br>

## A1

```{r, eval=F}
q1.data <- data.frame(read.table("data/DRPscores.txt", header = F, sep = ""))
colnames(q1.data) <- c("Group", "Score")
q1.data.treat <- q1.data[q1.data$Group == "Treat",]
q1.data.contr <- q1.data[q1.data$Group == "Control",]

###

Nt.c <- shapiro.test(q1.data.contr$Score)
Nt.t <- shapiro.test(q1.data.treat$Score)

###

library(pander)

x <- data.frame(Group = c("Treatment", "Control"), "P-Value" = c(Nt.t$p.value, Nt.c$p.value) )

pandoc.table(x,
             caption = "**Table 1:** P-values for Shapiro-Wilk tests for normality. The large p-values for both groups indicate that there is no evidence that either group is *not* normally distributed.",
             split.table = Inf)

###

VT <- var.test(q1.data.treat$Score, q1.data.contr$Score)

###

x <- data.frame("F" = VT$statistic, "P-Value" = VT$p.value)

pandoc.table(x,
             caption = "**Table 2:** Test statistic corresponding p-value for test of equality of variances. Since the p-value is greater than 0.05 (even if just so) we will conclude that the population variances can be assumed similar.",
             split.table = Inf)

###

tT <- t.test(x = q1.data.treat$Score, y = q1.data.contr$Score, alternative = "greater", var.equal = T)

###

x <- data.frame("T" = tT$statistic, "P-Value" = tT$p.value)
rownames(x) <- NULL

pandoc.table(x,
             caption = "**Table 3:** Test-statistc and corresponding p-value for one-tailed two-sample t-test.",
             split.table = Inf)
```

<br>
<br>

## A2

```{r, eval=F}
### Part A

x <- c(rep(1, 482), rep(0,18))
results <- t.test(x = x, mu = 0.90, alternative = "g")

x <- data.frame("Z" = results$statistic, "P-Value" = results$p.value)
rownames(x) <- NULL

pandoc.table(x,
             caption = "**Table Q2A:** Test-statistic and corresponding p-value for one-tailed Z-test.",
             split.table = Inf)

### Part B

x <- c(rep(1, 482), rep(0,18))
results <- t.test(x = x, mu = 0.95, alternative = "g")

x <- data.frame("Z" = results$statistic, "P-Value" = results$p.value)
rownames(x) <- NULL

pandoc.table(x,
             caption = "**Table Q2B:** Test-statistic and corresponding p-value for one-tailed Z-test.",
             split.table = Inf)
```

<br>
<br>

## A3
```{r, eval=F}
# Load data set

q3.data <- data.frame(read.table("data/harass.txt", header = T, sep = ""))

## Normality tests

x <- data.frame("P.value" = c(shapiro.test(q3.data$Test1)$p.value,
                              shapiro.test(q3.data$Test2)$p.value,
                              shapiro.test(q3.data$Test1 - q3.data$Test2)$p.value))
colnames(x) <- "P-Value"
rownames(x) <- c("Scores from Test 1", "Scores from Test 2", "Difference between Scores")

pandoc.table(x,
             caption = "**Table Q3A:** P-values from the Shapiro-Wilk normality test for our data. Since all the p-values are greater than 0.05 we will accept the null hypothesis that our data are normally distributed.",
             split.table = Inf)

## Hypothesis test for difference between mean scores

results <- t.test(q3.data$Test2, q3.data$Test1, paired = T)

x <- data.frame("S" = results$statistic, "P" = results$p.value)
colnames(x) <- c("Test Statistic", "P-Value")

pandoc.table(x,
             caption = "**Table Q3B:** The observed test statistic and p-value for the paired t-test. Since the p-value is greater than 0.05 we cannot conclude that the mean scores changed.",
             split.table = Inf)

## Confidence Interval

x <- data.frame("LB" = results$conf.int[1], "UB" = results$conf.int[2])
colnames(x) <- c("Lower Bound", "Upper Bound")

pandoc.table(x,
             caption = "**Table Q3C:** 95% confidence interval for the difference between the mean scores. Notice that the confidence interval includes 0, indicating that there is no significant evidence of a difference between the mean scores.",
             split.table = Inf)
```  

<br>
<br>

## A4