---
title: "STA 580 Final Exam"
author: "Andrew Deighan"
date: "April 29, 2017"
output: html_document
---

# Answers

<br>

## Question 1

  For code see appendix [A1](#a1).
  
> An educator believes that a new reading curriculum will help elementary school students improve some aspects of their reading ability. She arranges for a third-grade class of 21 students to take part in the new curriculum for an eight-week period. A control classroom of 23 third-graders follows the standard curriculum. At the end of the eight weeks, all students are given a Degree of Reading Power (DRP) test, which measures aspects of reading that the treatment is designed to improve “DRPscores.txt”.
>
> Test the hypothesis that the treatment group performed better than the control group on the test. State your conclusions.

```{r, include = F}

q1.data <- data.frame(read.table("data/DRPscores.txt", header = F, sep = ""))
colnames(q1.data) <- c("Group", "Score")
q1.data.treat <- q1.data[q1.data$Group == "Treat",]
q1.data.contr <- q1.data[q1.data$Group == "Control",]

```

  The size of our control group is 23 and the size of our treatment group is 21. Since these sample sizes are both less than 30 we should use a t-test of sample means. Before doing so however, we need to check that our assumption that the data are normally distributed is valid. To this end we will use the Shapiro-Wilk test for normality. The null hypothesis of the Shapiro-Wilk test is that the data are normally distributed and the alternative hypothesis is that they are not. Thus a small p-value (less than 0.05) indicates that the data are *not* normally distributed whereas a large p-value indicates that there is no significant evidence that the data are not normally distributed. Table 1 gives the p-values for the Shapiro-Wilk test for both groups. The large p-values indicate that we fail to reject the null hypothesis and conclude that the data are normally distributed.
  
```{r, include=F}

Nt.c <- shapiro.test(q1.data.contr$Score)
Nt.t <- shapiro.test(q1.data.treat$Score)

```

***

```{r, echo =F, results = "asis"}
library(pander)
panderOptions("table.caption.prefix", "")

x <- data.frame(Group = c("Treatment", "Control"), "P-Value" = c(Nt.t$p.value, Nt.c$p.value) )

pandoc.table(x,
             caption = "**Table 1:** P-values for Shapiro-Wilk tests for normality. The large p-values for both groups indicate that there is no evidence that either group is *not* normally distributed.",
             split.table = Inf)

```

***


  Next we need to test if the variances of the underlying populations for the two samples is significantly different. For this we will use an F-test for the equality of population variances. The null hypothesis for the F-test is that the two population variances are equal, the alternative is that they are not equal (for the two-tailed scenario, which is what we are interested in). The test-statistic for the F-test is the ratio of the two sample variances (sample 1 variance to sample 2 variance), the further away from 1 the test-statistic is the more likely it is that the null hypothesis is false. Under the null hypothesis (that the two population variances are equal), the test-statistic has an F-distribution with numerator degrees of freedom equal to the size of first sample minus 1, and denominator degrees of freedom equal to the size of the second sample minus 1. See below.

  $$ \text{F} = \frac{S_1^2}{S_2^2} \sim F_{(n_1 - 1)(n_2 - 2)} $$

  We can use the "var.test()" function in R to perform the above described F-test. For small p-values (< 0.05) we should reject the null hypothesis that the population variances are equal in favor of the alternative hypothesis that they are different. For large p-value we should fail to reject the null hypothesis and conclude that the population variances are equal. Table 2 reports the calculated F-statistic and corresponding p-value. The p-value is greater than 0.05 so we fail to reject the null hypothesis and conclude that the two populations have the same variance.
  
```{r, include=F}

VT <- var.test(q1.data.treat$Score, q1.data.contr$Score)

```
  
***

```{r, echo=F, results="asis"}

x <- data.frame("F" = VT$statistic, "P-Value" = VT$p.value)

pandoc.table(x,
             caption = "**Table 2:** Test statistic corresponding p-value for test of equality of variances. Since the p-value is greater than 0.05 (even if just so) we will conclude that the population variances can be assumed similar.",
             split.table = Inf)

```

***

  Now that we have verified our assumptions that the two populations have are normally distributed with equal variances, we will perform a one-tailed two-sample t-test for the difference of means. Our null hypothesis is that the mean score of students taught with the new curriculum is no greater than students taught under the old curriculum; our alternative hypothesis is that the mean score is higher.
  
  $$ \text{H}_o: \mu_t - \mu_c \leq 0 \space \space \space \space \space v.s. \space \space \space \space \text{H}_a: \mu_t - \mu_c > 0$$
  The test-statistic for this test is the difference between the sample means divided by the pooled sample variance. Under the null hypothesis this test-statistic has a t-distribution with degrees of freedom equal to the sum of the sample sizes minus 2.
  
  $$ \text{T} = \frac{\bar{x_t} - \bar{x_c}}{S_p  \sqrt{ \frac{1}{n_1} + \frac{1}{n_2} }} \sim{t_{n_1 + n_2 - 2}} \\  \\ \text{where:} \space \space \space S_p = \sqrt{ \frac{ (n_1 -1)S_1^2 + (n_2 - 1)S_2^2 }{n_1 + n_2 - 2} }$$

  The large a positive test-statistic we observe the more likely it is that the mean score of students taught under the new curriculum is greater than that of those taught under the old curriculum. We will use and alpha level of 0.05, so we will reject our null hypothesis if the p-value (probability of observing a value larger than the one we observe) of our observed test-stastic is less than 0.05. We can use the R function "t.test()" to perform this test. Table 3 reports observed test-statistic and corresponding p-value.
  
```{r, include=F}

tT <- t.test(x = q1.data.treat$Score, y = q1.data.contr$Score, alternative = "greater", var.equal = T)

```

***

```{r, echo=F, results="asis"}

x <- data.frame("T" = tT$statistic, "P-Value" = tT$p.value)
rownames(x) <- NULL

pandoc.table(x,
             caption = "**Table 3:** Test-statistc and corresponding p-value for one-tailed two-sample t-test.",
             split.table = Inf)

```

***

  Since our p-value is less than 0.05 we reject the null hypothesis that the mean scores did not differ in favor of the alternative hypothesis that they did. Thus, we conclude that the students taught under the new curriculum performed better on the test than students taught under the old curriculum.

<br>
<br>

## Question 2

  For code see appendix [A2](#a2)

> A company is rated as acceptable in quality control if more than 90% of units produced at
its facilities are found to be defect-free, and it is rated as excellent in quality control if
more than 95% are defect-free. Suppose that a random sample of 500 units is selected and
tested for defects, and that 18 units are found to have defects.
>
>a. Does this data show at the 5% level of significance that the company is acceptable?
>b. Does it show that the company is excellent? Construct a 95% confidence interval for
proportion of defect-free units.
>c. What sample size should a reliability engineer use to estimate this proportion to within
2% with 95% confidence if it is assumed that the proportion of units that are defect-free
is at least 90%?

  Estimated proportion defect-free:
  
  $$ \widehat{p} = \frac{500 - 18}{500} = .964 \rightarrow 96.4\% $$
  Approximate standard error of the proportion defect free:
  
  $$ \widehat{\text{SE}}[\widehat{p}] = \sqrt{\frac{\widehat{p}(1 - \widehat{p})}{n}} = \sqrt{\frac{.964*.036}{500}} \approx 0.00833 $$

<br>

### Part A

  One-tailed hypothesis test with alpha = 0.05.

* Null hypothesis The proportion of products defect-free is less than or equal to 0.90
    + $\text{p}_o \leq 0.90$
* Alternative hypothesis The proportion of products defect-free is greater than 0.90
    + $\text{p}_a > 0.90$

In order to test the above null hypothesis we will used a one-tailed Z-test with an alpha level of 0.05. The formula for the test statistic is given below:

  $$ \text{Z} = \frac{\widehat{p} - \text{p}_o}{\sqrt{\frac{\widehat{p}(1 - \widehat{p})}{n}}} \sim AN(0,1) $$

So in our case the test statistic is:

   $$ \text{Z} = \frac{0.964 - 0.90}{0.00833} \approx 7.71 $$
Using the "pnorm()" function in R we find that the probability of observing a test statisitic this large or larger under the null hypothesis is less than 0.05. Table Q2A reports the test statistic and p-value. Since the p-value is less than 0.05 (much less in fact) we reject the null hypothesis and conclude at a 5% level of significance that the company is acceptable (proportion of products defect free is greater than 0.90).

***

```{r, echo=F, results="asis"}

x <- data.frame("Z" = 7.71, "P-Value" = pnorm(7.71, lower.tail = F))
colnames(x) <- c("Test Statistic", "P-value")

pandoc.table(x,
             caption = "**Table Q2A:** Observed test-statistic and corresponding p-value for one-tailed Z-test.",
             split.table = Inf)

```

***

<br>
<br>

### Part B

  One-tailed hypothesis test with alpha = 0.05.

* Null hypothesis The proportion of products defect-free is less than or equal to 0.95
    + $\text{p_o} \leq 0.95$
* Alternative hypothesis The proportion of products defect-free is greater than 0.95
    + $\text{p_a} > 0.95$
    
    We will conduct this hypothesis test in just the same way as in part A, except now we will use $\text{p}_o = 0.95$. Thus our test statistic under these conditions is:
    
    $$ \text{Z} = \frac{0.964 - 0.95}{0.00833} \approx 1.687 $$
    
    Using the "pnorm()" function in R we find that the probability of observing a test statisitic this large or larger under the null hypothesis is slightly less than 0.05. Table Q2B reports the test statistic and p-value. Since the p-value is less than 0.05 (though close) we reject the null hypothesis and conclude at a 5% level of significance that the company is excellent (proportion of defect-free products is greater than 0.95).

***

```{r, echo=F, results="asis"}

x <- data.frame("Z" = 1.687, "P-Value" = pnorm(1.687, lower.tail = F))
colnames(x) <- c("Test Statistic", "P-value")

pandoc.table(x,
             caption = "**Table Q2B:** Observed test-statistic and corresponding p-value for one-tailed Z-test.",
             split.table = Inf)

```

***

<br>
<br>

### Part C

  We want to determine how large the sample size *n* must be in order to have an error margin *E* of 2% ($\pm 2\%$). Below we show the formula for the sample size *n* for a desired margin of error:
  
  $$ n = \text{p}(1- \text{p})*(\frac{Z_{\alpha/2}}{E})^2 $$
  Since we want a 95% confidence interval *Z* = 1.96. We already know we want *E* to be 0.02 and the question says that p is assumed to be 0.90 thus:

$$ n = 0.9*0.1*(\frac{1.96}{0.02})^2 \approx 864.26 \rightarrow 864 $$
  So, assuming the proportion of units defect free is at least 90%, if we want to estimate the proportion of products defect free within $\pm 2\%$ with 95% confidence we should have a sample size of 864.

<br>
<br>

## Question 3

  For code see appendix [A3](#a3)

> A large corporation requires that its employees attend a 1-day sexual harassment seminar.
The Director of Human Resources of this corporation would like to determine whether or
not the information presented in this seminar is retained over a long period of time. To
this end, a random sample of 40 employees is selected from recently hired employees
who are scheduled to take this seminar. Each of the employees in this sample completes a
test of knowledge concerning sexual harassment and related legal issues immediately
after the seminar, and then takes a similar test 6 months later. The scores are contained in
the file “harass.txt”.
>
>Does that data indicate at the 5% level of significance that the mean score has changed
after 6 months? Construct a 95% confidence interval for the difference between the
mean scores.
  
```{r, include=F}
# Load data set

q3.data <- data.frame(read.table("data/harass.txt", header = T, sep = ""))

```

  We are dealing with paired data here (difference between test score of the same subject at different time points) so we will use a paired t-test. We can do this using the "t.test()" function in R and setting the argument "paired" to **TRUE**, this tell the function that the data is paired. Since the question just asks whether the mean score has changed, and not in what direction it has changed, this will be a two-tailed test. The null hypothesis is that the mean difference between the scores is 0, the alternative hypothesis is that it is not equal to zero. For this test we will use an alpha level of 0.05. However, before doing the test we will check to see if the data are normally distributed using the Shapiro-Wilk test. The null hypothesis is that the data are normally distributed and the alternative hypothesis is that they are not (we will use an alpha level of 0.05). R has a built in function called "shapiro.test()". Table Q3A shows the results of the Shapiro-Wilk test for the scores from test 1, test 2, and the difference between the scores. Since all the p-values are greater than 0.05 we will accept the assumption that our data are normally distributed.

***

```{r, echo=F, results="asis"}

x <- data.frame("P.value" = c(shapiro.test(q3.data$Test1)$p.value,
                              shapiro.test(q3.data$Test2)$p.value,
                              shapiro.test(q3.data$Test1 - q3.data$Test2)$p.value))
colnames(x) <- "P-Value"
rownames(x) <- c("Scores from Test 1", "Scores from Test 2", "Difference between Scores")

pandoc.table(x,
             caption = "**Table Q3A:** P-values from the Shapiro-Wilk normality test for our data. Since all the p-values are greater than 0.05 we will accept the null hypothesis that our data are normally distributed.",
             split.table = Inf)

```

***

  Table Q3B gives the observed test statistic and p-value for the two sample t-test for the difference between scores. Since the p-value is greater than 0.05 we will accept the null hypothesis and conclude that there is not sufficient evidence to show that the mean score has changed over 6 months.

***

```{r, echo=F, results="asis"}

results <- t.test(q3.data$Test2, q3.data$Test1, paired = T)

x <- data.frame("S" = results$statistic, "P" = results$p.value)
rownames(x) <- NULL
colnames(x) <- c("Test Statistic", "P-Value")

pandoc.table(x,
             caption = "**Table Q3B:** The observed test statistic and p-value for the paired t-test. Since the p-value is greater than 0.05 we cannot conclude that the mean scores changed.",
             split.table = Inf)
```

***

  We can also use the output from the t.test function to give us a 95% confidence for the difference between the mean scores. Table Q3C reports this confidence interval. As we can see the confidence interval includes zero, once again indicating that there is insufficient evidence of a change in the mean scores.

***

```{r, echo=F, results="asis"}

x <- data.frame("LB" = results$conf.int[1], "UB" = results$conf.int[2])
colnames(x) <- c("Lower Bound", "Upper Bound")

pandoc.table(x,
             caption = "**Table Q3C:** 95% confidence interval for the difference between the mean scores. Notice that the confidence interval includes 0, indicating that there is no significant evidence of a difference between the mean scores.",
             split.table = Inf)
```  

***

<br>
<br>

## Question 4

 For code see appendix [A4](#a4)

> The goal for the mean time to resolve software problems by the software support group
of a large corporation is 24 hours. Suppose that 60 software problem items are randomly
selected from all such items over the past quarter, and the mean time to resolve the
problems was 22.4 hours with a standard deviation of 9.6 hours.
>
> a. Does this data show at the 10% level of significance that the mean resolution time is less
than 24 hours?
> b. Construct a 90% confidence interval for the mean resolution time.
> c. What sample size would be required to estimate the mean time to within 0.5 hours with
90% confidence if it is assumed that the standard deviation will be no more than 10
hours?

### Part A

One-tailed hypothesis test with alpha = 0.1.

* Null hypothesis: The mean resolution time is greater than or equal to 24 hours
    + $\mu_o \geq 24 \rightarrow \widehat{\mu} - \mu_o \geq 0$
* Alternative hypothesis: The mean resolution time is less than 24 hours
    + $\mu_a < 24 \rightarrow \widehat{\mu} - \mu_o < 0$

In order to test the above null hypothesis we will used a one-tailed Z-test with an alpha level of 0.05. The test statistic is given below:

  $$ \text{Z} = \frac{\widehat{\mu} - \mu_o}{\frac{\sigma}{\sqrt{n}}} \sim AN(0,1) $$

So in our case the test statistic is:

  $$ \text{Z} = \frac{22.4 - 24}{\frac{9.6}{\sqrt{60}}} \approx -1.291 $$
  Using the "pnorm()" function in R we find that the probability of observing a test statisitic this small or smaller under the null hypothesis is slightly less than 0.1. Table Q4A reports the test statistic and p-value. Since the p-value is less than 0.1 (though close) we reject the null hypothesis and conclude at a 10% level of significance that the mean resolution time is less than 24 hours. However, we are not very emphatic about our conclusion since the p-value is quite close to 0.1.

***

```{r, echo=F, results="asis"}

x <- data.frame("Z" = -1.291, "P-Value" = pnorm(-1.291, lower.tail = T))
colnames(x) <- c("Test Statistic", "P-value")

pandoc.table(x,
             caption = "**Table Q4A:** Observed test-statistic and corresponding p-value for one-tailed Z-test.",
             split.table = Inf)


```

***

<br>
<br>

### Part B

  The formula for a confidence interval of a mean (since sample size is greater than 30 we can be Central Limit Theorem assume the mean is normally distributed) is given below:
  
  $$ (1 - \alpha)\% \space \text{CI }[\mu] = \widehat{\mu} \pm z_{\alpha/2}*\frac{\sigma}{\sqrt{n}}$$
```{r, include=F}

z <- qnorm(0.95)

```
  
  Since we want a 90% confidence interval ($z_{\alpha/2} = 1.64$ found using the R function "qnorm()"), our confidence interval is:

$$ 90\% \space \text{CI }[\mu] = 22.4 \pm 1.64*\frac{9.6}{\sqrt{60}} \approx (20.37, 24.43)$$

<br>
<br>

### Part C

  We want to determine how large the sample size *n* must be in order to have an error margin *E* of 0.5 hours ($\pm 0.5$ hours) with 90% confidence. Below we show the formula for the sample size *n* for a desired margin of error:
  
  $$ n = (\frac{z_{\alpha/2} * \sigma }{E})^2 $$
  Since we want a 90% confidence interval *z* = 1.64. We already know we want *E* to be 0.5 hours and the question says that $\sigma$ is assumed to be no more than 10 hours thus:

$$ n = (\frac{1.64 * 10}{0.5})^2 = 1075.84 \rightarrow 1076 $$

  So, assuming the standard deviation is no more than 10 hours, if we want to estimate the mean resolution time within $\pm 0.5$ hours with 95% confidence we should have a sample size of 1076.



<br>
<br>

## Question 5

  For code see appendix [A5](#a5)

> A study of industries in North Texas compared the experience of entry-level managers in
telecommunication companies with the experience of entry-level managers in software services
companies. Suppose that a random sample of size 20 entry-level managers was
selected separately from each group of companies and the experience of each manager
was obtained. The data summary are:
>
>     Telecom (Sample 1):   mean = 4.7,   standard deviation = 1.75
>     Software (Sample 2):  mean = 6.0,   standard deviation = 0.75
>
> a. Does this data show that there is a difference at the 5% level of significance?
> b. Construct a 90% confidence interval for the difference between the means.

<br>
<br>

### Part A

Two-tailed hypothesis test with alpha = 0.05.

* Null hypothesis: There is no difference between telecommunication companies and sofware companies in the mean experience of entry-level managers.
    + $\text{D}_o = \mu_1 - \mu_2 = 0$
* Alternative hypothesis: The mean resolution time is less than 24 hours
    + $\text{D}_a = \mu_1 - \mu_2 \neq 0$

In order to test the above null hypothesis we will used a two-tailed t-test (sample sizes are less than 0.05) with an alpha level of 0.05. The test statistic is given below:

$$ \text{T} = \frac{(\widehat{\mu}_1 - \widehat{\mu}_2) - \text{D}_o} {\sqrt{ \frac{S^2_p}{n} + \frac{S^2_p}{n} }} \sim t_{n_1 + n_2 - 2} \\ \text{where: } \space \space \space S^2_p = \frac{ (n_1 - 1)S_1^2 + (n_2 - 1)S_2^2 }  {n_1 + n_2 - 2} $$

  Since we are doing a two-tailed test, we will reject the null hypothesis if the probability of observing a test statistic greater than or equal to the absolute value of our test statistic is less than 0.05.


So under our conditions our test statistic is:

$$ \text{T} = \frac{(4.7 - 6.0) - 0} {\sqrt{ \frac{S^2_p}{20} + \frac{S^2_p}{20} }} \sim t_{38} \\ \text{where: } \space \space \space S^2_p = \frac{ (19)1.75^2 + (19)0.75^2 }  {38} = \frac{1.75^2 + 0.75^2}{2} = \frac{3.625}{2} \\ \text{which gives: } \space \space \space \text{T} = \frac{-2.6} {\sqrt{ \frac{3.625}{5} }} \approx -3.054 $$

  Using the "pt()" function in R we find that the probability of observing a test statisitic with an absolute value this large or larger under the null hypothesis is less than 0.05. Table Q5A reports the test statistic and p-value. Since the p-value is less than 0.05 we reject the null hypothesis and conclude at a 5% level of significance that the mean experience of entry-level managers is not the same between telecommunications companies and software services companies.

***

```{r, echo=F, results="asis"}

x <- data.frame("T" = -3.054, "DF" = 38, "P-Value" = pt(3.054, df = 38, lower.tail = F))
colnames(x) <- c("Test Statistic", "Degrees of Freedom",  "P-value")

pandoc.table(x,
             caption = "**Table Q5A:** Observed test-statistic and corresponding p-value for two-tailed t-test.",
             split.table = Inf)


```

***


<br>
<br>

### Part B

  The formula for the confidence interval for the difference between the means is:

$$ (1 - \alpha)\% \space \text{CI [D]} = \widehat{\text{D}} \pm t_{\alpha/2, \space df}*\sqrt{ \frac{S^2_p}{n_1} + \frac{S^2_p}{n_2} }$$

```{r, include=F}
t <- qt(0.95, 38)
```

  We have 38 degrees of freedom and we want a 90% confidence interval, so using the "qt()" function in R we find that our  $t_{.05, \space 38} = 1.69$. Also our sample sizes are the same so our 90% confidence interval is:
  
  $$ 90\% \space \text{CI [D]} = -1.3 \pm 1.69*\sqrt{\frac{3.625}{20}} \approx (-2.02, -0.581)$$

  Thus we are 90% confident that the the difference between the mean experiance entry-level telecommunication managers and entry-level software managers is between -2.02 and 0.581.

<br>
<br>

## Question 6

<br>
<br>

# Appendix

<br>

## A1

```{r, eval=F}
q1.data <- data.frame(read.table("data/DRPscores.txt", header = F, sep = ""))
colnames(q1.data) <- c("Group", "Score")
q1.data.treat <- q1.data[q1.data$Group == "Treat",]
q1.data.contr <- q1.data[q1.data$Group == "Control",]

###

Nt.c <- shapiro.test(q1.data.contr$Score)
Nt.t <- shapiro.test(q1.data.treat$Score)

###

library(pander)

x <- data.frame(Group = c("Treatment", "Control"), "P-Value" = c(Nt.t$p.value, Nt.c$p.value) )

pandoc.table(x,
             caption = "**Table 1:** P-values for Shapiro-Wilk tests for normality. The large p-values for both groups indicate that there is no evidence that either group is *not* normally distributed.",
             split.table = Inf)

###

VT <- var.test(q1.data.treat$Score, q1.data.contr$Score)

###

x <- data.frame("F" = VT$statistic, "P-Value" = VT$p.value)

pandoc.table(x,
             caption = "**Table 2:** Test statistic corresponding p-value for test of equality of variances. Since the p-value is greater than 0.05 (even if just so) we will conclude that the population variances can be assumed similar.",
             split.table = Inf)

###

tT <- t.test(x = q1.data.treat$Score, y = q1.data.contr$Score, alternative = "greater", var.equal = T)

###

x <- data.frame("T" = tT$statistic, "P-Value" = tT$p.value)
rownames(x) <- NULL

pandoc.table(x,
             caption = "**Table 3:** Test-statistc and corresponding p-value for one-tailed two-sample t-test.",
             split.table = Inf)
```

<br>
<br>

## A2

```{r, eval=F}
### Part A

x <- data.frame("Z" = 7.71, "P-Value" = pnorm(7.71, lower.tail = F))
colnames(x) <- c("Test Statistic", "P-value")

pandoc.table(x,
             caption = "**Table Q2A:** Observed test-statistic and corresponding p-value for one-tailed Z-test.",
             split.table = Inf)

### Part B

x <- data.frame("Z" = 1.687, "P-Value" = pnorm(1.687, lower.tail = F))
colnames(x) <- c("Test Statistic", "P-value")

pandoc.table(x,
             caption = "**Table Q2B:** Observed test-statistic and corresponding p-value for one-tailed Z-test.",
             split.table = Inf)
```

<br>
<br>

## A3
```{r, eval=F}
# Load data set

q3.data <- data.frame(read.table("data/harass.txt", header = T, sep = ""))

## Normality tests

x <- data.frame("P.value" = c(shapiro.test(q3.data$Test1)$p.value,
                              shapiro.test(q3.data$Test2)$p.value,
                              shapiro.test(q3.data$Test1 - q3.data$Test2)$p.value))
colnames(x) <- "P-Value"
rownames(x) <- c("Scores from Test 1", "Scores from Test 2", "Difference between Scores")

pandoc.table(x,
             caption = "**Table Q3A:** P-values from the Shapiro-Wilk normality test for our data. Since all the p-values are greater than 0.05 we will accept the null hypothesis that our data are normally distributed.",
             split.table = Inf)

## Hypothesis test for difference between mean scores

results <- t.test(q3.data$Test2, q3.data$Test1, paired = T)

x <- data.frame("S" = results$statistic, "P" = results$p.value)
rownames(x) <- NULL
colnames(x) <- c("Test Statistic", "P-Value")

pandoc.table(x,
             caption = "**Table Q3B:** The observed test statistic and p-value for the paired t-test. Since the p-value is greater than 0.05 we cannot conclude that the mean scores changed.",
             split.table = Inf)

## Confidence Interval

x <- data.frame("LB" = results$conf.int[1], "UB" = results$conf.int[2])
colnames(x) <- c("Lower Bound", "Upper Bound")

pandoc.table(x,
             caption = "**Table Q3C:** 95% confidence interval for the difference between the mean scores. Notice that the confidence interval includes 0, indicating that there is no significant evidence of a difference between the mean scores.",
             split.table = Inf)
```  

<br>
<br>

## A4

```{r, eval=F}
### Part A
x <- data.frame("Z" = -1.291, "P-Value" = pnorm(-1.291, lower.tail = T))
colnames(x) <- c("Test Statistic", "P-value")

pandoc.table(x,
             caption = "**Table Q4A:** Observed test-statistic and corresponding p-value for one-tailed Z-test.",
             split.table = Inf)

### Part B
z <- qnorm(0.95)

```

<br>
<br>

## A5

```{r, eval=F}
## Part A
x <- data.frame("T" = -3.054, "DF" = 38, "P-Value" = pt(3.054, df = 38, lower.tail = F))
colnames(x) <- c("Test Statistic", "Degrees of Freedom",  "P-value")

pandoc.table(x,
             caption = "**Table Q5A:** Observed test-statistic and corresponding p-value for two-tailed t-test.",
             split.table = Inf)

## Part B
t <- qt(0.95, 38)
```

<br>
<br>

## A6